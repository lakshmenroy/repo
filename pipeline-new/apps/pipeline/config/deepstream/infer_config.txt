# Inference Configuration for Nozzlenet
# Primary GIE (PGIE) configuration

[property]
gpu-id=0
net-scale-factor=0.003921568627451
offsets=0.0;0.0;0.0
model-color-format=0
labelfile-path=/mnt/ssd/csi_pipeline/models/nozzlenet-v2/V250/labels.txt
model-engine-file=/mnt/ssd/model_repository/nozzlenet-v2/V253/ssd_resnet18_epoch_060-nozzlenet-batch-size-1.plan
infer-dims=3;480;480
uff-input-blob-name=input_1
batch-size=1
network-mode=0
num-detected-classes=6
interval=0
gie-unique-id=1
process-mode=1
network-type=0
cluster-mode=2
maintain-aspect-ratio=1
parse-bbox-func-name=NvDsInferParseCustomResnet
custom-lib-path=/opt/nvidia/deepstream/deepstream/lib/libnvds_infercustomparser.so
input-tensor-from-meta=0
output-tensor-meta=0

[class-attrs-all]
pre-cluster-threshold=0.4
eps=0.2
group-threshold=1